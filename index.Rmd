---
title: <span style="color:#034a94"> **Actividad 2**</span>
author: "Métodos y Simulación Estadística"
output:
  html_document:
    toc: no
    toc_depth: 2
    toc_float: yes
    code_folding: hide
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
library(summarytools)


c1 ="#FF7F00"  # naranja - color primario 
c2 ="#034A94"  # azul oscuro - color secundario
c3 ="#0EB0C6"  # azul claro - color terciario
c4 ="#686868"  # gris - color texto

# devtools::install_github("dgonxalex80/paqueteMETODOS")
library(paqueteMETODOS)
data(ventas)
```


```{r, echo=FALSE, out.width="100%", fig.align = "center"}
knitr::include_graphics("img/banner3.png")
```


El proceso de simulación constituye una herramienta poderosa para la estadística que se pueden emplear para entender relaciones complejas y estimar valores difíciles de calcular directamente. Para entenderlo utilizaremos se plantean los siguientes problemas:

</br></br>

# <span style="color:#034a94"> **Problema 1**</span>

<br/>

## <span style="color:#FF7F00">**Estimación del valor de $\pi$ **</span> 

La siguiente figura sugiere como estimar el valor de $\pi$ con una simulación. En la figura, un círculo con un área igual a $\pi/4$, está inscrito en un cuadrado cuya área es igual a 1. Se elige de forma aleatoria $n$ puntos dentro del cuadrado . La probabilidad de que un punto esté dentro del círculo es igual a la fracción del área del cuadrado que abarca a éste, la cual es $\pi/4$. Por tanto, se puede estimar el valor de $\pi/4$ al contar el número de puntos dentro del círculo, para obtener la estimación de $\pi/4$ . De este último resultado se encontrar una aproximación para el valor de $\pi$ . 


```{r, echo=FALSE, out.width="50%", fig.align = "center"}
knitr::include_graphics("img/pi.png")
```

<br/>

Pasos sugeridos:

a. Genere $n$ coordenadas $x$:  $X_{1}$, . . . , $X_{n}$. Utilice la distribución uniforme con valor mínimo de $0$ y valor máximo de $1$. La distribución uniforme genera variables aleatorias que tienen la misma probabilidad de venir de cualquier parte del intervalo $(0, 1)$. 

b. Genere $1000$ coordenadas $y$ : $Y_{1}, . . . , Y_{n}$, utilizando nuevamente la distribución uniforme con valor mínimo de $0$ y valor máximo de $1$.

c. Cada punto $(X_{i},Y_{i})$ se encuentra dentro del círculo si su distancia desde el centro $(0.5, 0.5)$ es menor a $0.5$. Para cada par $(X_{i},Y_{i})$ determine si la distancia desde el centro es menor a $0.5$. Esto último se puede realizar al calcular el valor $(X_{i}-0.5)^{2}+(Y_{i}-0.5)^{2}$, que es el cuadrado de la distancia, y al determinar si es menor que $0.25$.

d. ¿Cuántos de los puntos están dentro del círculo? ¿Cuál es su estimación de $\pi$? 

<br/>

<div class="content-box-gray">
### <span style="color:#686868">**Nota**</span>

* Con sólo 1000 puntos, es probable que la estimación presente un error de 0.05 o más. Una simulación con 10000 y 100000 puntos tiene mayores probabilidades de dar como resultado una estimación muy cercana al valor verdadero.

* funciones recomendadas : `runif()`, `funtion(){}`  

* **Entregable** : enlace en **RPubs** con informe 1

Problema tomado de Navidi(2006) 

</div>

</br></br></br>

# <span style="color:#034a94"> **Problema 2**</span>

</br>

## <span style="color:#FF7F00">**Propiedades de los estimadores**</span>

La simulación ayuda a entender y validad las propiedades de los estimadores estadísticos como son, insesgadez, eficiencia y la consistencia principalmente. El siguiente problema permite evidenciar las principales características de un grupo de estimadores propuestos para la estimación de un parámetro asociado a un modelo de probabilidad.


Sean  $X_{1}$, $X_{2}$, $X_{3}$ y $X_{4}$, una muestra aleatoria de tamaño $n = 4$ cuya población la conforma una distribución exponencial con parámetro $\theta$ desconocido. Determine las características de cada uno de los siguientes estimadores propuestos:

<br/>

* $\widehat{\theta_1} = \dfrac{X_{1} + X_{2}}{6} + \dfrac{X_3 + X_4}{3}$

<br/>

* $\widehat{\theta_2} = \dfrac{(X_1 + 2 X_2 + 3 X_3 + 4 X_4)}{5}$

<br/>

* $\widehat{\theta_3} = \dfrac{X_1 + X_2 + X_3 + X_4}{4}$

<br/>

* $\widehat{\theta_4} = \dfrac{\min\{X_1,X_2,X_3,X_4\} + \max\{X_1,X_2,X_3,X_4\}}{2}$



<br/>
<div class="content-box-gray">
### <span style="color:#686868">**Nota**</span>

* Genere una muestras de n=20, 50, 100 y 1000  para cada uno de los estimadores planteados.

* En cada caso evalúe las propiedades de insesgadez, eficiencia y consistencia 

* Suponga un valor para el parámetro $\theta$

* funciones recomendadas : `function(){}`,  `rexp()` ,  `data.frame()`,   `apply()`, `boxplot()`

* **Entregable** : enlace en **RPubs** con informe 2

</div>

<br/>



</br></br></br>

# <span style="color:#034a94"> **Problema 3**</span>

<br/>

## <span style="color:#FF7F00">**Teorema del Límite Central**</span> 

</br>

El Teorema del Límite Central es uno de los más importantes en la inferencia estadística y habla sobre la convergencia de los estimadores como la proporción muestral a la distribución normal. Algunos autores afirman que esta aproximación es bastante buena a partir del umbral $n > 30$.

A continuación se describen los siguientes pasos para su verificación:

</br>

a. Realice una simulación en la cual genere una población de $n=1000$ (Lote), donde el porcentaje de individuos (supongamos plantas) enfermas sea del 50%.

</br>

b. Genere una función que permita: 
* Obtener una muestra aleatoria de la población y 
* Calcule el estimador de la proporción muestral $\widehat{p}$ para un tamaño de muestra dado $n$. 

</br>

c. Repita el escenario anterior (b) $n=500$ veces y analice los resultados en cuanto al comportamiento de los $500$ resultados del estimador $\widehat{p}$. ¿Qué tan simétricos o sesgados son los resultados obtenidos? y ¿qué se puede observar en cuanto a la variabilidad?. Realice en su informe un comentario sobre los resultados obtenidos.

</br>

d. Repita los puntos  b y c para tamaños de muestra $n=5$, $10$, $15$, $20$, $30$, $50$, $60$, $100$, $200$, $500$. Compare los resultados obtenidos para los diferentes tamaños de muestra en cuanto a la normalidad. Utilice pruebas de bondad y ajuste (shapiro wilks :`shspiro.test()`) y métodos gráficos (gráfico de normalidad: `qqnorm()`). Comente en su informe los resultados obtenidos

</br>

e. Repita toda la simulación (puntos a – d), pero ahora para lotes con 10% de plantas enfermas y de nuevo para lotes con un 90% de plantas enfermas. Concluya sobre los resultados del ejercicio.

</br>

<div class="content-box-gray">
### <span style="color:#686868">**Nota**</span>

* funciones recomendadas : `rbinom()` , `data.frame()`,   `sapply()`

**Entregable** : enlace en **RPubs** con informe 3
</div>

</br></br></br>

# <span style="color:#034a94">**Problema 4**</span>


<br/>

## <span style="color:#FF7F00">**Estimacción boostrap**</span> 

</br>


Cuando se extrae una muestra de una población que no es normal y se requiere estimar un intervalo de confianza se pueden utilizar los métodos de estimación **bootstrap**. Esta metodología supone que se puede reconstruir la población objeto de estudio mediante un muestreo con reemplazo de la muestra que se tiene.  Existen varias versiones del método. Una presentación básica del método se describe a continuación:

<br/>

El artículo de In-use Emissions from Heavy Duty Dissel Vehicles (J.Yanowitz, 2001) presenta las mediciones de eficiencia de combustible en millas/galón de una muestra de siete camiones. Los datos obtenidos son los siguientes: 7.69, 4.97, 4.56, 6.49, 4.34, 6.24 y 4.45. Se supone que es una muestra aleatoria de camiones y que se desea construir un intervalo de confianza del 95 % para la media  de la eficiencia de combustible de esta población. No se tiene información de la distribución de los datos. El método bootstrap permite construir intervalos de confianza del 95 % - Para ilustrar el método suponga que coloca los valores de la muestra en una caja y extrae uno al azar. Este correspondería al primer valor de la muestra bootstrap $X^{∗}_{1}$. Después de anotado el valor se regresa $X^{∗}_{1}$  a la caja y se extrae el valor $X^{∗}_{2}$ , regresandolo nuevamente. Este procedimiento se repite hasta completar una muestra de tamaño $n$, $X^{∗}_{1}$,$X^{∗}_{2}$,$X^{∗}_{2}$,\cdot $X^{∗}_{n}$, conformando la muestra bootstrap.

Es necesario extraer un gran número de muestras (suponga k = 1000). Para cada una de las muestra bootstrap obtenidas se calcula la media $\bar{X^{∗}_{i}}$, obteniéndose un valor para cada muestra. El intervalo de confianza queda conformado por los percentiles $P_{2.5}$ y $P_{97.5}$. Existen dos métodos para estimarlo:

<br/><br/>

|        |                                              |
|:-------|:--------------------------------------------:|
|Método 1| $(P_{2.5}; P_{97.5})$                        |
|Método 2| $(2\bar{X} − P_{97.5}; 2\bar{X} − P_{2.5})$  |
|        |                                              |

<br/>

Construya el intervalo de confianza por los dos métodos y compare los resultados obtenidos. Comente los resultados. Confiaría en estas estimaciones?

<br/>
<br/>
<div class="content-box-gray">
### <span style="color:#686868">**Nota**</span>

* las muestras bootstrap se pueden obtener a partir de muestreo aleatorio con repetición (o también llamado con sustitución)

* **Entregable** : enlace en **RPubs** con informe 4

* funciones recomendadas : `sample()` , `apply()`, `quantile()`

Problema tomado de Navidi(2006) 
</div>


</br></br></br>


# <span style="color:#034a94">**Problema 5**</span>

<br/>

## <span style="color:#FF7F00">**Relaciones entre la potencia, el tamaño de los efectos y el tamaño de la muestra**</span> 

</br>

El "efecto del tamaño" (o "tamaño del efecto", en inglés "effect size") en el contexto de la prueba de hipótesis se refiere a la magnitud de la diferencia o la fuerza de la relación que se está investigando entre las variables. En otras palabras, mide la cantidad de cambio o la importancia práctica de los resultados, más allá de simplemente determinar si una diferencia es estadísticamente significativa. El tamaño del efecto es crucial porque, incluso si una prueba estadística muestra que un resultado es significativo (es decir, rechazas la hipótesis nula), el tamaño del efecto te dice si esa diferencia es realmente importante en un sentido práctico o clínico. Por ejemplo, un estudio podría encontrar que un nuevo medicamento reduce la presión arterial de manera estadísticamente significativa, pero el tamaño del efecto te indicaría si la reducción es lo suficientemente grande como para tener relevancia clínica. En resumen, el tamaño del efecto proporciona una medida complementaria a la significancia estadística, ayudando a interpretar el verdadero impacto o importancia de los resultados encontrados.

</br>

En este problema, nos centraremos en una aplicación que requiere la aplicación de la prueba t de Student para comparar las medias entre dos grupos. En este contexto evaluaremos cómo el efecto de los tamaños o las diferencias en los tamaños muestrales de los grupos influyen en la potencia de la prueba. De manera formal, la potencia se define como la probabilidad de rechazar la hipótesis nula cuando la hipótesis alternativa es verdadera. De forma más coloquial, la potencia es la capacidad de una prueba estadística para identificar un efecto si este realmente existe. En general, desequilibrios muy marcados en los tamaños de muestra tienden a reducir la potencia estadística, incluso cuando se asocian con tamaños de efecto considerables, lo que aumenta la probabilidad de cometer un error de tipo II. Para fundamentar esta afirmación, debes analizar diferentes resultados computacionales que se presentan a continuación.

</br></br>


### <span style="color:#FF7F00">**Caso 1: Variando los tamaños de los efectos (d)**</span>

En los códigos del archivo llamado **caso1.R**, para cada tamaño fijo de los efectos $d$, se modela la relación entre el tamaño muestral y la potencia (manteniendo constante el nivel de significancia $\alpha=0.05$). En las figuras se visualizan los resultados para tamaño de efecto muy pequeño ($d=0.1$), pequeño ($d=0.2$), mediano ($d=0.5$) y grande ($d=0.8$). Repite el análisis usando 5 valores distintos del nivel de significancia.  ¿Cambian los resultados? ¿Qué ocurre cuando el tamaño de muestra de los grupos que se comparan es de $20$, $60$, $100$ y $140$? Analiza y compara los resultados.

</br></br>

### <span style="color:#FF7F00">**Caso 2: Variando los tamaños muestrales**</span>

En los códigos del archivo llamado **caso2.R**, se modela la relación entre el tamaño del efecto $d$ y la potencia (manteniendo constante el nivel de significancia $\alpha=0.05$). Para ello, se considera los siguientes tamaños de muestra, donde $n_1$ es el número de sujetos en el grupo 1 y $n_2$ es el número de sujetos en el grupo 2:
    
* $n_1=28$, $n_2=1406$ : $n_1$ representa el $2$ % del tamaño total de la muestra de $1434$.
* $n_1=144$, $n_2=1290$ : $n_1$ representa el $10$ % del tamaño total de la muestra de $1434$.
* $_n1=287$, $n_2=1147$ : $n_1$ representa el $20$ % del tamaño total de la muestra de $1434$.
* $n_1=430$, $n_2=1004$ : $n_1$ representa el $30$ % del tamaño total de la muestra de $1434$.
* $n_1=574$, $n_2=860$  : $n_1$ representa el $40$ % del tamaño total de la muestra de $1434$.
* $n_1=717$, $n_2=717$ : grupos de igual tamaño (esto es óptimo porque conduce a la potencia más alta para un tamaño de efecto dado).

En la figura resultante, se trazaron las curvas de potencia para la prueba t de Student, en función del tamaño del efecto, asumiendo una tasa de error Tipo I del $5$ %. La comparación de diferentes curvas de potencia (basadas en el tamaño de la muestra de cada grupo) en el mismo gráfico es una representación visual útil de este análisis. En la figura también se trazó una línea discontinua horizontal en un nivel de potencia aceptable del 80% y una línea vertical en el tamaño del efecto que tendría que estar presente en nuestros datos para alcanzar el 80 % de potencia. Se observa que el tamaño del efecto debe ser superior a 0.54 para alcanzar un nivel de potencia aceptable dados tamaños de grupo altamente desequilibrados de $n_1=28$ y $n_2=1406$, en comparación con todos los demás escenarios que conducen al 100% de potencia. Repite el análisis usando $5$ valores distintos del nivel de significancia.  ¿Cambian los resultados? ¿Qué ocurre cuando $n_1=28$ y $n_2=1406$?  Analiza y compara los resultados.

</br></br>

### **Referencia**: 

* Teoría de Probabilidad y Estadística Matemática,  Dr. rer. nat. Humberto LLinás Solano,
Departamento de Matemáticas y Estadística, Universidad del Norte (Barranquilla, Colombia)


</br></br>

#### <span style="color:#696969">**Código caso1.R**</span>

```{r, eval=FALSE}

#Gráfica 1

#Se necesita el paquete pwr 
if(!require(pwr)){install.packages("pwr");library("pwr")}

# t-TEST
# Se aplicará power.t.test del paquete stats (ya en R). Calcula la potencia de la prueba t de una o dos muestras, o determina los parámetros para obtener un valor particular de la potencia.

d<-seq(.1,2,by=.1) # 20 tamaños de los efectos
n<-1:150 # Tamaños muestrales

t.test.power.effect <-as.data.frame(do.call("cbind",lapply(1:length(d),function(i)
{
  sapply(1:length(n),function(j)
  {
    power.t.test(n=n[j],d=d[i],sig.level=0.05,power=NULL,type= "two.sample")$power
  })
})))

# Si algunas potencias no se pueden calcular, se ajustan a cero:
t.test.power.effect[is.na(t.test.power.effect)] <- 0 
colnames(t.test.power.effect)<-paste (d,"effect size")

#Graficando los resultados

prueba <-t.test.power.effect #data frame de 150 X 20 (para graficar)
cuts_num<-c(2,5,8) # cortes

#Cortes basados en: Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates, Publishers.
cuts_cat<-c("pequeño","medio","grande") 

columnas <- 1:ncol(prueba) #Lista de los valores 1:20
color_linea<-rainbow(length(columnas), alpha=.5) # Lista de 20 colores
grosor_linea=3 # Grosor de la línea

#Para el tipo de línea: (“blank”, “solid”, “dashed”, “dotted”, “dotdash”, “longdash”, “twodash”) ó  (0, 1, 2, 3, 4, 5, 6). 
#Note que lty = “solid” is idéntica a lty=1.

tipo_linea <- rep(1,length(color_linea))        #Repetir length(color)=20 veces el 1
tipo_linea[cuts_num]<-c(2:(length(cuts_num)+1)) #Asignar 2, 3, 4 en las posiciones 2, 5, 8 de tipo_linea

#Resaltar posiciones importantes
cuts_num<-c(2,5,8) # Cortes

#Cortes basados en: Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates, Publishers.
cuts_cat<-c("pequeño","medio","grande") 
color_linea[cuts_num]<-c("black")

efecto <- d # Listado de los 20 valores de 20
efecto[cuts_num] <- cuts_cat  #Reemplazar en "efecto" las posiciones cuts_num (2, 5, 8) por las categorías de cuts_cat

par(fig=c(0,.8,0,1),new=TRUE)

#Gráfica
plot(1, type="n", #no produce puntos ni líneas
     frame.plot=FALSE, 
     xlab="Tamaño muestral", ylab="Potencia", 
     xlim=c(1,150),  ylim=c(0,1), 
     main="t-Test", axes = FALSE)

#Editando los ejes, grid, etc.
abline(v=seq(0,150,by=10), col = "lightgray", lty = "dotted") # Grid vertical
abline(h=seq(0,1,by=.05), col = "lightgray", lty = "dotted")  # Grid horizontal
axis(1,seq(0,150,by=10)) # Números en eje X
axis(2,seq(0,1,by=.05))  # Números en eje Y

#Plot de las lineas 
#columnas <- 1:ncol(prueba) # lista de los valores 1:20
for(i in 1:length(columnas)) #length(columnas)=20
{
  lines(1:150,
        #prueba (data frame de 150 X 20, para graficar)
        #columna <- 1:ncol(prueba) listado de valores 1:20 
        prueba[,columnas[i]], #filtrar "prueba" para valor de columna
        col=color_linea[i],   #color_linea[cuts_num]<-c("black")
        lwd=grosor_linea,     #grosor de cada linea
        lty=tipo_linea[i]     #tipo_linea[cuts_num]<-c(2:(length(cuts_num)+1))
  )
}

#Leyendas
par(fig=c(.65,1,0,1),new=TRUE)
plot.new()
legend("top",legend=efecto, col=color_linea, lwd=3, lty=tipo_linea, title="Tamaño efecto", 
       bty="n" #Opciones: o (complete box), n (no box), 7, L, C, U
)

#Gráfica 2

#plot using ggplot2

#library(ggplot2)
#library(reshape)
#library(plotly)

obj <- cbind(size=1:150, prueba) #Agregando el tamaño al data frame "prueba" 

# Usar melt y unir con "effect" para el mapeo
#El data frame "obj" se reconstruye con respecto al parámetro id="size". 
melted <- cbind(reshape::melt(obj, id="size"), effect=rep(d,each=150)) 

p<- ggplot(data=melted, aes(x=size, y=value, color=as.factor(effect))) + 
  geom_line(size=0.7,alpha=.5) +
  ylab("Potencia") + 
  xlab("Tamaño muestral") + 
  ggtitle("t-Test")+
  theme_bw() +
  #guides(fill=guide_legend(title="Efecto"))
  #scale_fill_discrete(name = "Efecto")
  #labs(fill='Efecto') 
  #scale_fill_manual("Efecto"#,values=c("orange","red")
  scale_color_discrete(name = "Tamaño del efecto")    

# Interactive plot
plotly::ggplotly(p)



```

</br></br>

#### <span style="color:#696969">**Código caso2.R**</span>

```{r, eval=FALSE}
#library(dplyr)    
#library(tidyr)    #Para manipulación de datos: separate, gather, spread
#library(ggplot2)  
#library(plotly)   #Para curvas de potencias interactivas
#library(pwr)      #Para cálculo de las potencias

#Generar cálculos de las potencias con la funcion pwr.t2n.test.
#Es un t-test para 2 muestras con tamaños diferentes 
#Aquí: d es el tamaño del efecto, Power= potencia de la prueba= 1-beta): 

#pwr.t2n.test(n1 = NULL, n2= NULL, d = NULL, sig.level = 0.05, power = NULL,  alternative = c("two.sided",  "less","greater"))

ptab <- cbind(NULL, NULL)       

for (i in seq(0,1, length.out = 200)){
  pwrt1 <- pwr.t2n.test(n1 = 28, n2 = 1406, 
                        sig.level = 0.05, power = NULL, 
                        d = i, alternative="two.sided")
  pwrt2 <- pwr.t2n.test(n1 = 144, n2 = 1290, 
                        sig.level = 0.05, power = NULL, 
                        d = i, alternative="two.sided")
  pwrt3 <- pwr.t2n.test(n1 = 287, n2 = 1147, 
                        sig.level = 0.05, power = NULL, 
                        d = i, alternative="two.sided")
  pwrt4 <- pwr.t2n.test(n1 = 430, n2 = 1004, 
                        sig.level = 0.05, power = NULL, 
                        d = i, alternative="two.sided")
  pwrt5 <- pwr.t2n.test(n1 = 574, n2 = 860, 
                        sig.level = 0.05, power = NULL, 
                        d = i, alternative="two.sided")
  pwrt6 <- pwr.t2n.test(n1 = 717, n2 = 717, 
                        sig.level = 0.05, power = NULL, 
                        d = i, alternative="two.sided")
  
  #Es un data frame de tamaño 200 por 12: 
  ptab <- rbind(ptab, cbind(pwrt1$d, pwrt1$power,
                            pwrt2$d, pwrt2$power,
                            pwrt3$d, pwrt3$power,
                            pwrt4$d, pwrt4$power,
                            pwrt5$d, pwrt5$power,
                            pwrt6$d, pwrt6$power))
}


#Es un data frame de tamaño 200 por 13 (la 1ra columna es ID)
ptab <- cbind(seq_len(nrow(ptab)), ptab)

colnames(ptab) <- c("id","n1=28, n2=1406;effect size","n1=28, n2=1406;power",
                    "n1=144, n2=1290;effect size","n1=144, n2=1290;power",
                    "n1=287, n2=1147;effect size","n1=287, n2=1147;power",
                    "n1=430, n2=1004;effect size","n1=430, n2=1004;power",
                    "n1=574, n2=860;effect size","n1=574, n2=860;power",
                    "n1=717, n2=717;effect size","n1=717, n2=717;power")

#gather se usa  para "reunir" un par key-value. En este caso, en 3 columnas: ID, variables y respuestas numericas
temp1 <- ptab %>% as.data.frame() %>%   gather(key = name, value = val, 2:13)

#Separar celdas en columnas, de acuerdo a una condición (sep=). En este caso, se separó "name" en dos columnas: samples y pruebas 
temp2 <- temp1 %>%   separate(col = name, into = c("samples", "pruebas"), sep = ";")


#La función spread hace lo opuesto a gather. Son funciones complementarias. 
#Es decir, si al resultado de aplicar la función spread le aplicamos la función gather llegamos al dataset original.
temp3 <- temp2 %>%   spread(key = pruebas, value = val)

#Convertir la variable "samples" a factor.
temp3$samples <- factor(temp3$samples, 
                        levels = c("n1=28, n2=1406", "n1=144, n2=1290", 
                                   "n1=287, n2=1147", "n1=430, n2=1004",
                                   "n1=574, n2=860", "n1=717, n2=717")
)

#Gráfica
p<- ggplot(temp3, aes(x = `effect size`, y = power, color = samples)) +
  geom_line(size=1) + 
  
  theme_bw() + 
  theme(axis.text=element_text(size=10), 
        axis.title=element_text(size=10), 
        legend.text=element_text(size=10)) +
  
  geom_vline(xintercept = .54, linetype = 2) +
  geom_hline(yintercept = 0.80, linetype = 2)+
  
  labs(x="Effect size", y="Power") +
  scale_color_discrete(name = "Sampling size") 

# so simple to make interactive plots
plotly::ggplotly(p)
```

